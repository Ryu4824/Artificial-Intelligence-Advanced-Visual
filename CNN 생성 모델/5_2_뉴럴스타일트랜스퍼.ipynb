{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO2l/UJHn096A4oQ3ULwIOw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OawZru9pnFzR","executionInfo":{"status":"ok","timestamp":1718888921736,"user_tz":-540,"elapsed":25686,"user":{"displayName":"류재영","userId":"06247944364332023076"}},"outputId":"f9fdcc9f-1242-4ee9-e1ea-aa0c96fc1d55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["from keras.models import Model\n","from IPython.display import display\n","from IPython.display import Image as _Imgdis\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","\n","image_path = '/content/gdrive/MyDrive/pytest_img/opencv/'\n","save_path = '/content/gdrive/MyDrive/pytest_img/_generated_images'\n","\n","# 원본 이미지와 참조 이미지 경로 설정\n","base_image_path = image_path+'seoul.png'\n","style_reference_image_path = image_path+'starnight.png'"],"metadata":{"id":"r9tsS_3CnTIm","executionInfo":{"status":"ok","timestamp":1718888926163,"user_tz":-540,"elapsed":4431,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","# 기본 저장 경로 밑에 neural_style 이라는 폴더를 만든다\n","if not os.path.exists(os.path.join(save_path, \"neural_style/\")):\n","  os.makedirs(os.path.join(os.path.join(save_path, \"neural_style/\")))"],"metadata":{"id":"pV2Hj0wNn-F-","executionInfo":{"status":"ok","timestamp":1718888926164,"user_tz":-540,"elapsed":17,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 원본 이미지와 참조 이미지의 사이즈가 비슷해야 잘 된다\n","# 두 이미지를 같은 크기로 하였을 때 출력에 무리가 없는지 확인한다\n","img_height = 400 # 이미지의 높이\n","img_width = 600 # 이미지의 너비\n","display(_Imgdis(filename=base_image_path, height=img_height, width=img_width))\n","display(_Imgdis(filename=style_reference_image_path, height=img_height, width=img_width))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":817,"output_embedded_package_id":"1ZeaIDw7pAaVGf4zLEsmFGn7edVybo_76"},"id":"ceMMVngQoS9H","executionInfo":{"status":"ok","timestamp":1718888946415,"user_tz":-540,"elapsed":20267,"user":{"displayName":"류재영","userId":"06247944364332023076"}},"outputId":"784e1e3e-b82d-41a0-dddc-708b1177aea7"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#이미지를 읽고, 전처리하는 함수를 정의한다\n","import numpy as np\n","import tensorflow as tf\n","def preprocess_image(image_path):\n","  img = load_img(image_path, target_size=(img_height, img_width)) # 같은 사이즈로 맞춘다\n","  img = img_to_array(img)\n","  img = np.expand_dims(img, axis=0) # 맨 앞에 배치 차원을 추가한다\n","  img = tf.keras.applications.vgg19.preprocess_input(img)\n","  return img"],"metadata":{"id":"Oae333mPowaI","executionInfo":{"status":"ok","timestamp":1718888946419,"user_tz":-540,"elapsed":53,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def deprocess_image(img):\n","  img = img.reshape((img_height, img_width, 3)) # 이미지를 위에서 정의한 사이즈로 변환\n","  # VGG19.preprocess_input()에서는 전처리를 수행하면서 RGB 채널에서 아래 세 값을 빼주므로 다시 더하여 원래 색상으로 복원한다.\n","  # 아래 세 값은 ImageNet의 평균 필셀 값\n","  img[:, :, 0] += 103.939\n","  img[:, :, 1] += 116.779\n","  img[:, :, 2] += 123.68\n","  img = img[:, :, ::-1] # 채널의 순서를 VGG19가 학습된 RGB → BGR로 변경한다\n","  img = np.clip(img, 0, 255).astype(\"uint8\") # 값을 0~255 사이로 제한한다\n","  return img"],"metadata":{"id":"CP3VRj4lpq-1","executionInfo":{"status":"ok","timestamp":1718888946428,"user_tz":-540,"elapsed":60,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.vgg19 import VGG19\n","model = VGG19(weights=\"imagenet\", include_top=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVqNs0f6rT5U","executionInfo":{"status":"ok","timestamp":1718888947416,"user_tz":-540,"elapsed":1046,"user":{"displayName":"류재영","userId":"06247944364332023076"}},"outputId":"8397a927-b679-45d8-b439-5d6b04772a14"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["# 모델의 레이어들을 그 출력 결과와 함께 가져온다\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","# 모델에 입력을 넣으면 모델의 모든 레이어 출력을 포함하는 딕셔너리를 반환하는 모델 생성\n","# 일반적으로 Functional API에서 outputs에는 최종 출력층을 넣지만,\n","# 여기에서는 필요한 레이어의 출력값을 쉽게 가져오도록 모든 레이어의 출력을 반환하게 한다\n","feature_extractor = Model(inputs=model.inputs, outputs=outputs_dict)"],"metadata":{"id":"4Xk6Cs6zrXn6","executionInfo":{"status":"ok","timestamp":1718888947416,"user_tz":-540,"elapsed":150,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["outputs_dict"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCmOy4PSrbWa","executionInfo":{"status":"ok","timestamp":1718888947417,"user_tz":-540,"elapsed":151,"user":{"displayName":"류재영","userId":"06247944364332023076"}},"outputId":"0c427292-cf42-4d8e-b6ac-51e1c0cbb18f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_1': <KerasTensor: shape=(None, None, None, 3) dtype=float32 (created by layer 'input_1')>,\n"," 'block1_conv1': <KerasTensor: shape=(None, None, None, 64) dtype=float32 (created by layer 'block1_conv1')>,\n"," 'block1_conv2': <KerasTensor: shape=(None, None, None, 64) dtype=float32 (created by layer 'block1_conv2')>,\n"," 'block1_pool': <KerasTensor: shape=(None, None, None, 64) dtype=float32 (created by layer 'block1_pool')>,\n"," 'block2_conv1': <KerasTensor: shape=(None, None, None, 128) dtype=float32 (created by layer 'block2_conv1')>,\n"," 'block2_conv2': <KerasTensor: shape=(None, None, None, 128) dtype=float32 (created by layer 'block2_conv2')>,\n"," 'block2_pool': <KerasTensor: shape=(None, None, None, 128) dtype=float32 (created by layer 'block2_pool')>,\n"," 'block3_conv1': <KerasTensor: shape=(None, None, None, 256) dtype=float32 (created by layer 'block3_conv1')>,\n"," 'block3_conv2': <KerasTensor: shape=(None, None, None, 256) dtype=float32 (created by layer 'block3_conv2')>,\n"," 'block3_conv3': <KerasTensor: shape=(None, None, None, 256) dtype=float32 (created by layer 'block3_conv3')>,\n"," 'block3_conv4': <KerasTensor: shape=(None, None, None, 256) dtype=float32 (created by layer 'block3_conv4')>,\n"," 'block3_pool': <KerasTensor: shape=(None, None, None, 256) dtype=float32 (created by layer 'block3_pool')>,\n"," 'block4_conv1': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block4_conv1')>,\n"," 'block4_conv2': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block4_conv2')>,\n"," 'block4_conv3': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block4_conv3')>,\n"," 'block4_conv4': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block4_conv4')>,\n"," 'block4_pool': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block4_pool')>,\n"," 'block5_conv1': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block5_conv1')>,\n"," 'block5_conv2': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block5_conv2')>,\n"," 'block5_conv3': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block5_conv3')>,\n"," 'block5_conv4': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block5_conv4')>,\n"," 'block5_pool': <KerasTensor: shape=(None, None, None, 512) dtype=float32 (created by layer 'block5_pool')>}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 콘텐츠 즉, 원본 이미지의 기본 형상에 대한 손실함수 정의\n","# base_img는 원본 이미지를,\n","# combination_img는 스타일이 적용된 후의 조합 이미지로 둘의 차이를 손실값으로 정의한다\n","# 변환된 값이 원본 이미지와 지나치게 차이가 나지 않도록 조절하는 데 사용된다\n","# 너무 같아도 안되므로, 스타일 손실과의 사이에서 적절한 밸런스를 찾는다\n","def content_loss(base_img, combination_img):\n","  return tf.reduce_sum(tf.square(combination_img - base_img))"],"metadata":{"id":"ZOoq35GAuagi","executionInfo":{"status":"ok","timestamp":1718888947417,"user_tz":-540,"elapsed":136,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def gram_matrix(x):\n","  x = tf.transpose(x, (2, 0, 1)) # (높이, 너비, 채널) → (채널, 높이, 너비) 순서로 바꾼다\n","  features = tf.reshape(x, (tf.shape(x)[0], -1)) # 각 채널을 행으로, 나머지는 -1로 (높이x너비) 열로 삼아 2D 행렬 구성\n","  gram = tf.matmul(features, tf.transpose(features)) # 만들어진 2D features를 그 전치와 행렬곱하여 그람 행렬을 만든다\n","\n","  return gram"],"metadata":{"id":"yVL0nf2jvYbT","executionInfo":{"status":"ok","timestamp":1718888947417,"user_tz":-540,"elapsed":108,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 스타일, 즉 참조 이미지가 갖는 스타일에 대한 손실함수를 정의\n","# 참조 이미지와 스타일이 적용된 후의 이미지가 얼마나 차이나는지를 손실값으로 정의한다\n","# 스타일은 개별 픽셀의 차이보다는 채널 사이의 상호관계 차이로 보는 것이 더 타당하기 때문\n","def style_loss(style_img, combination_img):\n","  S = gram_matrix(style_img) # 스타일 이미지의 그람 행렬 계산\n","  C = gram_matrix(combination_img) # 스타일이 적용된 후의 이미지인 combination_img의 그람 행렬 계산\n","  channels = 3\n","  size = img_height * img_width\n","  return tf.reduce_sum(tf.square(S-C)) / (4.0 * (channels ** 2) * (size ** 2))"],"metadata":{"id":"_mNwOOxQvaKw","executionInfo":{"status":"ok","timestamp":1718888947417,"user_tz":-540,"elapsed":104,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def total_variation_loss(x):\n","  a = tf.square(x[:, : img_height - 1, : img_width - 1, :] - x[:, 1:, : img_width - 1, :])\n","  b = tf.square(x[:, : img_height - 1, : img_width - 1, :] - x[:, : img_height - 1, 1:, :])\n","  return tf.reduce_sum(tf.pow(a+b, 1.25))"],"metadata":{"id":"O5L3a7Znvbs2","executionInfo":{"status":"ok","timestamp":1718888947418,"user_tz":-540,"elapsed":95,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 스타일을 추출하기 위해 사용할 네트워크 층\n","style_layer_names = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \"block5_conv1\"]\n","\n","# 콘텐츠(원본 이미지)에서 기본 형상 특징을 추출하기 위해 사용할 네트워크 층\n","content_layer_name = \"block5_conv2\" # 콘텐츠 손실에 사용할 층\n","\n","# 스타일을 얼마나 원본 이미지에 반영할 것인지를 결정하는 가중치 설정\n","total_variation_weight = 1e-6 # 총 변동 손실의 기여 가중치 (이미지를 얼마나 매끄럽게 표현할 것인가)\n","style_weight = 1e-6 # 스타일 손실의 기여 가중치 (전체 이미지에서 반영할 스타일의 비중)\n","content_weight = 2.5e-8 # 콘텐츠 손실의 기여 가중치 (전체 이미지에서 반영할 콘텐츠의 비중)"],"metadata":{"id":"XeouO3SmveE7","executionInfo":{"status":"ok","timestamp":1718888947419,"user_tz":-540,"elapsed":95,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 조합된 이미지, 원본 이미지, 참조 이미지를 입력으로 받아 그들의 차이를 토대로 최종 손실을 계산한다\n","def compute_loss(combination_image, base_image, style_reference_image):\n","  # 원본 이미지, 참조 이미지, 조합된 이미지를 배치 차원으로 결합한다 (3, 높이, 너비, 채널)\n","  input_tensor = tf.concat([base_image, style_reference_image, combination_image], axis=0)\n","  features = feature_extractor(input_tensor) # 입력 데이터를 모델을 사용하여 처리한 결과로부터 특징을 추출\n","  loss = tf.zeros(shape=()) # 손실을 0으로 초기화\n","  layer_features = features[content_layer_name] # 콘텐츠 손실에 사용할 층의 특징을 추출\n","  base_image_features = layer_features[0, :, :, :] # 원본 이미지의 특징을 추출\n","  combination_features = layer_features[2, :, :, :] # 조합 이미지의 특징을 추출\n","  loss += content_weight * content_loss(base_image_features, combination_features) # 콘텐츠 손실을 계산하고, 이를 콘텐츠 손실 가중치와 곱한 뒤, 전체 손실에 추가한다\n","\n","  for layer_name in style_layer_names: # 스타일 추출에 사용할 층\n","    layer_features = features[layer_name] # 스타일 손실에 사용할 층의 특징을 추출\n","    style_reference_features = layer_features[1, :, :, :] # 스타일 이미지의 특징을 추출\n","    combination_features = layer_features[2, :, :, :] # 조합 이미지의 특징을 추출\n","    style_loss_value = style_loss(style_reference_features, combination_features) # 각 층의 스타일 손실 계산\n","    loss += (style_weight / len(style_layer_names)) * style_loss_value # 스타일 손실을 (스타일 손실 가중치/층 수)와 곱한 뒤, 전체 손실에 추가한다 (층의 모든 계산 결과를 누적)\n","  loss += total_variation_weight * total_variation_loss(combination_image) # 이미지의 매끄러움에 관계되는 조합 이미지의 총 변동 손실을 계산하고, 이를 총 변동 손실 가중치와 곱한 뒤, 전체 손실에 추가한다\n","  return loss"],"metadata":{"id":"f2UCblCvvgFB","executionInfo":{"status":"ok","timestamp":1718889509808,"user_tz":-540,"elapsed":558,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def compute_loss_and_grads(combination_image, base_image, style_reference_image):\n","  with tf.GradientTape() as tape: # 그라디언트 계산\n","    # 조합 이미지, 원본 이미지, 참조 이미지를 사용하여 최종 손실값을 계산한다\n","    loss = compute_loss(combination_image, base_image, style_reference_image)\n","\n","  # 최종 손실값에 대한 그라디언트를 계산하여 손실을 최소화하는 방향과 크기를 파악한다\n","  grads = tape.gradient(loss, combination_image)\n","  return loss, grads"],"metadata":{"id":"U4xFC00MvvYR","executionInfo":{"status":"ok","timestamp":1718889510371,"user_tz":-540,"elapsed":3,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.SGD(\n","  tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=100.0, decay_steps=100, decay_rate=0.90\n","  )\n",")"],"metadata":{"id":"kjsFSICXv_VC","executionInfo":{"status":"ok","timestamp":1718889513984,"user_tz":-540,"elapsed":3615,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["base_image = preprocess_image(base_image_path)\n","style_reference_image = preprocess_image(style_reference_image_path)\n","combination_image = tf.Variable(preprocess_image(base_image_path))# tf.GradientTape()을 사용할 수 있도록 tf.Variable()로 변경 가능한 텐서로 만든다"],"metadata":{"id":"aabgRT3MwFpa","executionInfo":{"status":"ok","timestamp":1718889514891,"user_tz":-540,"elapsed":912,"user":{"displayName":"류재영","userId":"06247944364332023076"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","iterations = 4000\n","for i in range(1, iterations + 1):\n","  loss, grads = compute_loss_and_grads(combination_image, base_image, style_reference_image)\n","  optimizer.apply_gradients([(grads, combination_image)]) # 옵티마이저를 이용하여 grads가 적은 방향으로 조합 이미지 업데이트\n","  if i % 100 == 0:\n","    print(f\"{i}번째 반복: loss={loss:.2f}\")\n","    img = deprocess_image(combination_image.numpy()) # 이미지 복원 함수로 출력할 수 있는 상태를 만든다\n","    fname = f\"combination_image_at_iteration_{i}.png\" # 파일 이름 설정\n","    keras.utils.save_img(os.path.join(save_path, \"neural_style/\", fname), img) # 100번째마다 이미지 저장"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bo47pKahwUqO","executionInfo":{"status":"ok","timestamp":1718891296683,"user_tz":-540,"elapsed":1747963,"user":{"displayName":"류재영","userId":"06247944364332023076"}},"outputId":"0db06d76-1ba9-4cc9-e644-ccfa8ed6ef78"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["100번째 반복: loss=12426.99\n","200번째 반복: loss=9811.43\n","300번째 반복: loss=8782.51\n","400번째 반복: loss=8215.18\n","500번째 반복: loss=7848.68\n","600번째 반복: loss=7589.55\n","700번째 반복: loss=7395.44\n","800번째 반복: loss=7244.43\n","900번째 반복: loss=7123.60\n","1000번째 반복: loss=7024.71\n","1100번째 반복: loss=6942.58\n","1200번째 반복: loss=6873.45\n","1300번째 반복: loss=6814.52\n","1400번째 반복: loss=6763.96\n","1500번째 반복: loss=6720.33\n","1600번째 반복: loss=6682.49\n","1700번째 반복: loss=6649.49\n","1800번째 반복: loss=6620.63\n","1900번째 반복: loss=6595.28\n","2000번째 반복: loss=6573.00\n","2100번째 반복: loss=6553.32\n","2200번째 반복: loss=6535.92\n","2300번째 반복: loss=6520.52\n","2400번째 반복: loss=6506.85\n","2500번째 반복: loss=6494.70\n","2600번째 반복: loss=6483.89\n","2700번째 반복: loss=6474.25\n","2800번째 반복: loss=6465.65\n","2900번째 반복: loss=6457.95\n","3000번째 반복: loss=6451.08\n","3100번째 반복: loss=6444.92\n","3200번째 반복: loss=6439.42\n","3300번째 반복: loss=6434.49\n","3400번째 반복: loss=6430.08\n","3500번째 반복: loss=6426.12\n","3600번째 반복: loss=6422.58\n","3700번째 반복: loss=6419.40\n","3800번째 반복: loss=6416.54\n","3900번째 반복: loss=6413.98\n","4000번째 반복: loss=6411.68\n"]}]}]}